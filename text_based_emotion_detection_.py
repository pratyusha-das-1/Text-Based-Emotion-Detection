# -*- coding: utf-8 -*-
"""Text-Based Emotion Detection .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VskL52IGXwm5E5kzWq-HzthIr73iLfwG
"""

pip install xgboost scikit-learn numpy

!pip install neattext

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import neattext.functions as nfx
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,classification_report, confusion_matrix
import joblib

df = pd.read_csv("emotion_dataset.csv")
df.head()

print(df.columns)

df['clean_text'] = df['text'].astype(str)
df['clean_text'] = df['clean_text'].apply(nfx.remove_stopwords)
df['clean_text'] = df['clean_text'].apply(nfx.remove_punctuations)

X = df['clean_text']
y = df['Emotion']

vectorizer = TfidfVectorizer()
X_vec = vectorizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

import xgboost as xgb


model = xgb.XGBClassifier(
    n_estimators=100,
    learning_rate=0.05,
    max_depth=5,
    random_state=42,
    use_label_encoder=False,
    eval_metric='mlogloss'
)


model.fit(X_train_tfidf, y_train_encoded)

y_pred_encoded = model.predict(X_test_tfidf)
y_pred = le.inverse_transform(y_pred_encoded)

y_pred_encoded = model.predict(X_test_tfidf)

y_pred = le.inverse_transform(y_pred_encoded)

accuracy = accuracy_score(y_test, y_pred)
print(f"Recognition Accuracy: {accuracy * 100:.2f}%")

present_labels = np.unique(y_test)
present_labels_encoded = le.transform(present_labels)

print("\nClassification Report:")
print(classification_report(
    y_test, y_pred,
    labels=present_labels,
    target_names=present_labels
))


cm = confusion_matrix(
    y_test, y_pred,
    labels=present_labels
)

plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=present_labels,
            yticklabels=present_labels)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

joblib.dump(model, "emotion_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")
print("âœ… Model and vectorizer saved successfully.")

model = joblib.load("emotion_model.pkl")
vectorizer = joblib.load("tfidf_vectorizer.pkl")

def predict_emotion(text):
    clean = nfx.remove_stopwords(text)
    clean = nfx.remove_punctuations(clean)
    vec = vectorizer.transform([clean])
    pred_encoded = model.predict(vec)
    pred_label = le.inverse_transform(pred_encoded)
    return pred_label[0]

while True:
    user_input = input("Enter a sentence (or type 'exit'): ")
    if user_input.lower() == 'exit':
        break
    emotion = predict_emotion(user_input)
    print("Predicted Emotion:", emotion)

